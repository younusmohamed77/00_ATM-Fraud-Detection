{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baeb5618",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-15T19:00:07.557337Z",
     "iopub.status.busy": "2025-02-15T19:00:07.556882Z",
     "iopub.status.idle": "2025-02-15T19:00:13.552225Z",
     "shell.execute_reply": "2025-02-15T19:00:13.551260Z"
    },
    "papermill": {
     "duration": 6.002463,
     "end_time": "2025-02-15T19:00:13.554404",
     "exception": false,
     "start_time": "2025-02-15T19:00:07.551941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Cell 1: Imports and Warnings\n",
    "# ===============================\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "sns.set()  # Seaborn style\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "779cf24f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T19:00:13.563156Z",
     "iopub.status.busy": "2025-02-15T19:00:13.562496Z",
     "iopub.status.idle": "2025-02-15T19:00:18.093800Z",
     "shell.execute_reply": "2025-02-15T19:00:18.092499Z"
    },
    "papermill": {
     "duration": 4.537206,
     "end_time": "2025-02-15T19:00:18.095616",
     "exception": false,
     "start_time": "2025-02-15T19:00:13.558410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (227845, 28)\n",
      "Test Data Shape: (56962, 27)\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Cell 2: Read the Dataset\n",
    "# ===============================\n",
    "\n",
    "# Extra CSV files\n",
    "location_df = pd.read_csv('/kaggle/input/fraudulent-financial-transaction-prediction/Geo_scores.csv')\n",
    "propindex_df = pd.read_csv('/kaggle/input/fraudulent-financial-transaction-prediction/Lambda_wts.csv')\n",
    "nettat_df = pd.read_csv('/kaggle/input/fraudulent-financial-transaction-prediction/Qset_tats.csv')\n",
    "vqs_df = pd.read_csv('/kaggle/input/fraudulent-financial-transaction-prediction/instance_scores.csv')\n",
    "\n",
    "# Main training set\n",
    "dataset_df = pd.read_csv('/kaggle/input/fraudulent-financial-transaction-prediction/train.csv')\n",
    "\n",
    "# Main test set\n",
    "test_df = pd.read_csv('/kaggle/input/fraudulent-financial-transaction-prediction/test_share.csv')\n",
    "\n",
    "print(\"Training Data Shape:\", dataset_df.shape)\n",
    "print(\"Test Data Shape:\", test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4be217ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T19:00:18.103633Z",
     "iopub.status.busy": "2025-02-15T19:00:18.103245Z",
     "iopub.status.idle": "2025-02-15T19:00:18.218381Z",
     "shell.execute_reply": "2025-02-15T19:00:18.216969Z"
    },
    "papermill": {
     "duration": 0.12135,
     "end_time": "2025-02-15T19:00:18.220397",
     "exception": false,
     "start_time": "2025-02-15T19:00:18.099047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TRAINING DATA INFO ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 227845 entries, 0 to 227844\n",
      "Data columns (total 28 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   id              227845 non-null  int64  \n",
      " 1   Group           227845 non-null  object \n",
      " 2   Per1            227845 non-null  float64\n",
      " 3   Per2            227845 non-null  float64\n",
      " 4   Per3            227845 non-null  float64\n",
      " 5   Per4            227845 non-null  float64\n",
      " 6   Per5            227845 non-null  float64\n",
      " 7   Per6            227845 non-null  float64\n",
      " 8   Per7            227845 non-null  float64\n",
      " 9   Per8            227845 non-null  float64\n",
      " 10  Per9            227845 non-null  float64\n",
      " 11  Dem1            227845 non-null  float64\n",
      " 12  Dem2            227845 non-null  float64\n",
      " 13  Dem3            227845 non-null  float64\n",
      " 14  Dem4            227845 non-null  float64\n",
      " 15  Dem5            227845 non-null  float64\n",
      " 16  Dem6            227845 non-null  float64\n",
      " 17  Dem7            227845 non-null  float64\n",
      " 18  Dem8            227845 non-null  float64\n",
      " 19  Dem9            227845 non-null  float64\n",
      " 20  Cred1           227845 non-null  float64\n",
      " 21  Cred2           227845 non-null  float64\n",
      " 22  Cred3           227845 non-null  float64\n",
      " 23  Cred4           227845 non-null  float64\n",
      " 24  Cred5           227845 non-null  float64\n",
      " 25  Cred6           227845 non-null  float64\n",
      " 26  Normalised_FNT  227845 non-null  float64\n",
      " 27  Target          227845 non-null  int64  \n",
      "dtypes: float64(25), int64(2), object(1)\n",
      "memory usage: 48.7+ MB\n",
      "\n",
      "--- TEST DATA INFO ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56962 entries, 0 to 56961\n",
      "Data columns (total 27 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   id              56962 non-null  int64  \n",
      " 1   Group           56962 non-null  object \n",
      " 2   Per1            56962 non-null  float64\n",
      " 3   Per2            56962 non-null  float64\n",
      " 4   Per3            56962 non-null  float64\n",
      " 5   Per4            56962 non-null  float64\n",
      " 6   Per5            56962 non-null  float64\n",
      " 7   Per6            56962 non-null  float64\n",
      " 8   Per7            56962 non-null  float64\n",
      " 9   Per8            56962 non-null  float64\n",
      " 10  Per9            56962 non-null  float64\n",
      " 11  Dem1            56962 non-null  float64\n",
      " 12  Dem2            56962 non-null  float64\n",
      " 13  Dem3            56962 non-null  float64\n",
      " 14  Dem4            56962 non-null  float64\n",
      " 15  Dem5            56962 non-null  float64\n",
      " 16  Dem6            56962 non-null  float64\n",
      " 17  Dem7            56962 non-null  float64\n",
      " 18  Dem8            56962 non-null  float64\n",
      " 19  Dem9            56962 non-null  float64\n",
      " 20  Cred1           56962 non-null  float64\n",
      " 21  Cred2           56962 non-null  float64\n",
      " 22  Cred3           56962 non-null  float64\n",
      " 23  Cred4           56962 non-null  float64\n",
      " 24  Cred5           56962 non-null  float64\n",
      " 25  Cred6           56962 non-null  float64\n",
      " 26  Normalised_FNT  56962 non-null  float64\n",
      "dtypes: float64(25), int64(1), object(1)\n",
      "memory usage: 11.7+ MB\n",
      "\n",
      "Training columns: ['Per1', 'Per2', 'Per3', 'Per4', 'Per5', 'Per6', 'Per7', 'Per8', 'Per9', 'Dem1', 'Dem2', 'Dem3', 'Dem4', 'Dem5', 'Dem6', 'Dem7', 'Dem8', 'Dem9', 'Cred1', 'Cred2', 'Cred3', 'Cred4', 'Cred5', 'Cred6', 'Normalised_FNT', 'Target']\n",
      "Test columns: ['Per1', 'Per2', 'Per3', 'Per4', 'Per5', 'Per6', 'Per7', 'Per8', 'Per9', 'Dem1', 'Dem2', 'Dem3', 'Dem4', 'Dem5', 'Dem6', 'Dem7', 'Dem8', 'Dem9', 'Cred1', 'Cred2', 'Cred3', 'Cred4', 'Cred5', 'Cred6', 'Normalised_FNT']\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Cell 3: Quick Info and Dropping Insignificant Columns\n",
    "# ===============================\n",
    "\n",
    "print(\"--- TRAINING DATA INFO ---\")\n",
    "dataset_df.info()\n",
    "\n",
    "print(\"\\n--- TEST DATA INFO ---\")\n",
    "test_df.info()\n",
    "\n",
    "# The columns 'id' and 'Group' were found insignificant in previous analysis\n",
    "# We drop them from both training and test data\n",
    "dataset_df.drop(columns=['id','Group'], inplace=True, errors='ignore')\n",
    "test_df.drop(columns=['id','Group'], inplace=True, errors='ignore')\n",
    "\n",
    "# Check the columns after dropping\n",
    "print(\"\\nTraining columns:\", dataset_df.columns.tolist())\n",
    "print(\"Test columns:\", test_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "257158a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T19:00:18.229408Z",
     "iopub.status.busy": "2025-02-15T19:00:18.229023Z",
     "iopub.status.idle": "2025-02-15T19:00:18.391504Z",
     "shell.execute_reply": "2025-02-15T19:00:18.390147Z"
    },
    "papermill": {
     "duration": 0.169136,
     "end_time": "2025-02-15T19:00:18.393605",
     "exception": false,
     "start_time": "2025-02-15T19:00:18.224469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (159491, 26)\n",
      "Validation shape: (68354, 26)\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Cell 4: Train/Validation Split\n",
    "# ===============================\n",
    "\n",
    "# 'Target' is our Y\n",
    "train_df, validation_df = train_test_split(\n",
    "    dataset_df, \n",
    "    train_size=0.7, \n",
    "    random_state=1, \n",
    "    stratify=dataset_df['Target']\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Validation shape:\", validation_df.shape)\n",
    "\n",
    "# Separate features and target\n",
    "X_train = train_df.drop('Target', axis=1)\n",
    "y_train = train_df['Target']\n",
    "\n",
    "X_val = validation_df.drop('Target', axis=1)\n",
    "y_val = validation_df['Target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ee05986",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T19:00:18.402579Z",
     "iopub.status.busy": "2025-02-15T19:00:18.402190Z",
     "iopub.status.idle": "2025-02-15T19:00:18.553374Z",
     "shell.execute_reply": "2025-02-15T19:00:18.552135Z"
    },
    "papermill": {
     "duration": 0.158095,
     "end_time": "2025-02-15T19:00:18.555346",
     "exception": false,
     "start_time": "2025-02-15T19:00:18.397251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Class distribution in y_train before oversampling ---\n",
      "Target\n",
      "0    159215\n",
      "1       276\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Class distribution in y_train after oversampling ---\n",
      "Target\n",
      "0    159215\n",
      "1    159215\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Cell 5: Handling Class Imbalance\n",
    "# ===============================\n",
    "\n",
    "print(\"--- Class distribution in y_train before oversampling ---\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_res, y_train_res = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"\\n--- Class distribution in y_train after oversampling ---\")\n",
    "print(y_train_res.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e549411",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T19:00:18.565155Z",
     "iopub.status.busy": "2025-02-15T19:00:18.564642Z",
     "iopub.status.idle": "2025-02-15T19:00:19.291753Z",
     "shell.execute_reply": "2025-02-15T19:00:19.290703Z"
    },
    "papermill": {
     "duration": 0.734327,
     "end_time": "2025-02-15T19:00:19.293681",
     "exception": false,
     "start_time": "2025-02-15T19:00:18.559354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Cell 6: Outlier Capping (IQR)\n",
    "# ===============================\n",
    "\n",
    "def iqr_capping(df):\n",
    "    \"\"\"\n",
    "    Caps values outside the [Q1-1.5*IQR, Q3+1.5*IQR] range for each numeric column.\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "            q1 = df[col].quantile(0.25)\n",
    "            q3 = df[col].quantile(0.75)\n",
    "            iqr = q3 - q1\n",
    "            lower_limit = q1 - (1.5 * iqr)\n",
    "            upper_limit = q3 + (1.5 * iqr)\n",
    "            df[col] = np.where(df[col] < lower_limit, lower_limit, df[col])\n",
    "            df[col] = np.where(df[col] > upper_limit, upper_limit, df[col])\n",
    "\n",
    "# Apply outlier capping to training, validation, and test sets\n",
    "iqr_capping(X_train_res)\n",
    "iqr_capping(X_val)\n",
    "iqr_capping(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be48575d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T19:00:19.304044Z",
     "iopub.status.busy": "2025-02-15T19:00:19.303646Z",
     "iopub.status.idle": "2025-02-15T19:00:19.561148Z",
     "shell.execute_reply": "2025-02-15T19:00:19.559207Z"
    },
    "papermill": {
     "duration": 0.265765,
     "end_time": "2025-02-15T19:00:19.563489",
     "exception": false,
     "start_time": "2025-02-15T19:00:19.297724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Cell 7: Scaling the Features\n",
    "# ===============================\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on oversampled X_train\n",
    "scaler.fit(X_train_res)\n",
    "\n",
    "# Transform X_train_res, X_val, and test_df\n",
    "X_train_scl = pd.DataFrame(scaler.transform(X_train_res), columns=X_train_res.columns)\n",
    "X_val_scl   = pd.DataFrame(scaler.transform(X_val),        columns=X_val.columns)\n",
    "X_test_scl  = pd.DataFrame(scaler.transform(test_df),      columns=test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f52501c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T19:00:19.572956Z",
     "iopub.status.busy": "2025-02-15T19:00:19.572562Z",
     "iopub.status.idle": "2025-02-15T19:01:26.010462Z",
     "shell.execute_reply": "2025-02-15T19:01:26.009160Z"
    },
    "papermill": {
     "duration": 66.447552,
     "end_time": "2025-02-15T19:01:26.014897",
     "exception": false,
     "start_time": "2025-02-15T19:00:19.567345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest training complete!\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Cell 8: Random Forest Model Training\n",
    "# ===============================\n",
    "\n",
    "# Initialize the Random Forest\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train on the oversampled, outlier-capped, scaled data\n",
    "rf_model.fit(X_train_scl, y_train_res)\n",
    "\n",
    "print(\"Random Forest training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ae22403",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T19:01:26.023541Z",
     "iopub.status.busy": "2025-02-15T19:01:26.023152Z",
     "iopub.status.idle": "2025-02-15T19:01:26.747682Z",
     "shell.execute_reply": "2025-02-15T19:01:26.746228Z"
    },
    "papermill": {
     "duration": 0.730958,
     "end_time": "2025-02-15T19:01:26.749497",
     "exception": false,
     "start_time": "2025-02-15T19:01:26.018539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[68224    12]\n",
      " [   37    81]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9995    0.9998    0.9996     68236\n",
      "           1     0.8710    0.6864    0.7678       118\n",
      "\n",
      "    accuracy                         0.9993     68354\n",
      "   macro avg     0.9352    0.8431    0.8837     68354\n",
      "weighted avg     0.9992    0.9993    0.9992     68354\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Cell 9: Evaluate on Validation Set\n",
    "# ===============================\n",
    "\n",
    "y_val_pred = rf_model.predict(X_val_scl)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_val_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_val_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c59ab88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T19:01:26.758479Z",
     "iopub.status.busy": "2025-02-15T19:01:26.758076Z",
     "iopub.status.idle": "2025-02-15T19:01:27.288492Z",
     "shell.execute_reply": "2025-02-15T19:01:27.287332Z"
    },
    "papermill": {
     "duration": 0.536763,
     "end_time": "2025-02-15T19:01:27.290145",
     "exception": false,
     "start_time": "2025-02-15T19:01:26.753382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test Predictions (Head) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prediction\n",
       "0           0\n",
       "1           0\n",
       "2           0\n",
       "3           0\n",
       "4           0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Cell 10: Predict on the Test Set\n",
    "# ===============================\n",
    "\n",
    "test_predictions = rf_model.predict(X_test_scl)\n",
    "\n",
    "# Convert to a DataFrame (optional if you want to save)\n",
    "prediction_df = pd.DataFrame({\n",
    "    \"Prediction\": test_predictions\n",
    "})\n",
    "\n",
    "print(\"--- Test Predictions (Head) ---\")\n",
    "display(prediction_df.head())\n",
    "\n",
    "# Optionally, save predictions:\n",
    "# prediction_df.to_csv(\"test_predictions.csv\", index=False)\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda103a9",
   "metadata": {
    "papermill": {
     "duration": 0.003791,
     "end_time": "2025-02-15T19:01:27.298163",
     "exception": false,
     "start_time": "2025-02-15T19:01:27.294372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6673442,
     "sourceId": 10758711,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 83.568809,
   "end_time": "2025-02-15T19:01:28.124168",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-15T19:00:04.555359",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
